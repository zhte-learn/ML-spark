{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BDV8w-nApEj0"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('DLD_project_bagging').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive_new')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvg-IiucpTNs",
        "outputId": "8cef3672-677d-4b8d-e4b2-d01d10dad77d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive_new\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"parquet\").load(\"/content/drive_new/MyDrive/cleaned_dataset\")"
      ],
      "metadata": {
        "id": "2akJsJd4pMCD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDF, testDF = df.randomSplit([.8, .2], seed=42)\n",
        "print(f\"\"\"There are {trainDF.count()} rows in the training set, and {testDF.count()} in the test set\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E0ZE_qZppn0",
        "outputId": "123e25ac-f254-4961-c2b9-7d01edf77e76"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 737972 rows in the training set, and 184535 in the test set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VectorAssembler, OneHotEncoder, StringIndexer, StandartScaler for Multiply Entries**"
      ],
      "metadata": {
        "id": "hLgqAUu-Ew__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.feature import VectorAssembler, OneHotEncoder, StringIndexer, StandardScaler\n",
        "\n",
        "categorical_cols = [field for (field, dataType) in trainDF.dtypes if dataType == \"string\"]\n",
        "index_output_cols = [x + \"Index\" for x in categorical_cols]\n",
        "ohe_output_cols = [x + \"OHE\" for x in categorical_cols]\n",
        "\n",
        "string_indexer = StringIndexer(inputCols = categorical_cols, outputCols = index_output_cols, handleInvalid = \"skip\")\n",
        "ohe_encoder = OneHotEncoder(inputCols = index_output_cols, outputCols = ohe_output_cols)\n",
        "\n",
        "numeric_cols = [field for (field, dataType) in trainDF.dtypes if ((dataType == \"double\") and (field != \"actual_worth\"))]\n",
        "\n",
        "assembler_inputs = ohe_output_cols + numeric_cols\n",
        "vec_assembler = VectorAssembler(inputCols = assembler_inputs, outputCol = \"features\")"
      ],
      "metadata": {
        "id": "z1NQhK6UPngu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
        "\n",
        "lr_with_scaler = LinearRegression(labelCol = \"actual_worth\", featuresCol = \"scaled_features\")\n",
        "pipeline_with_scaler = Pipeline(stages = [string_indexer, ohe_encoder, vec_assembler, scaler, lr_with_scaler])\n",
        "lr_model_with_scaler = pipeline_with_scaler.fit(trainDF)\n",
        "lr_prediction_with_scaler = lr_model_with_scaler.transform(testDF)"
      ],
      "metadata": {
        "id": "XNmF6pNyP3uE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_prediction_with_scaler.select(\"actual_worth\", \"prediction\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boVcKUfdEN88",
        "outputId": "a3b6a925-d807-49ae-9371-62011e29bba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------------+\n",
            "|actual_worth|         prediction|\n",
            "+------------+-------------------+\n",
            "|    262493.0|  -362426.625497828|\n",
            "|    390000.0|-175553.64861687622|\n",
            "|    312500.0|-153460.60358589678|\n",
            "|    650000.0|  394106.2402005645|\n",
            "|    500000.0| 402905.47590058204|\n",
            "|   1280000.0| 402905.47590058204|\n",
            "|    925000.0|  608769.6089686223|\n",
            "|    250000.0|  638205.9010586096|\n",
            "|   1150000.0|  734364.4552192347|\n",
            "|    750000.0|  748481.2146516371|\n",
            "+------------+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ],
      "metadata": {
        "id": "3-dy2P7nbNbw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regression_evaluator = RegressionEvaluator(predictionCol = \"prediction\", labelCol = \"actual_worth\", metricName = \"rmse\")\n",
        "rmse_scaler = regression_evaluator.evaluate(lr_prediction_with_scaler)\n",
        "print(f\"RMSE is {rmse_scaler:.1f}\")\n",
        "\n",
        "r2_scaler = regression_evaluator.setMetricName(\"r2\").evaluate(lr_prediction_with_scaler)\n",
        "print(f\"R2 is {r2_scaler}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTy25APnQWEA",
        "outputId": "3d847834-d889-442c-8ae1-ee6a3d544463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE is 672571.9\n",
            "R2 is 0.6201786575789652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision tree**\n",
        "\n",
        "Tree-based methods can naturally handle categorical variables. In spark.ml, pass the categorical columns to the StringIndexer, and the decision tree can take care of the rest."
      ],
      "metadata": {
        "id": "vtQ8hbDtGIk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "\n",
        "dt = DecisionTreeRegressor(labelCol=\"actual_worth\", featuresCol=\"features\")\n",
        "\n",
        "assembler_inputs_tree = index_output_cols + numeric_cols\n",
        "vec_assembler_tree = VectorAssembler(inputCols=assembler_inputs_tree, outputCol=\"features\")\n",
        "\n",
        "stages_tree = [string_indexer, vec_assembler_tree, dt]\n",
        "pipeline_tr = Pipeline(stages=stages_tree)\n",
        "\n",
        "dt.setMaxBins(135)\n",
        "\n",
        "pipeline_model_tr = pipeline_tr.fit(trainDF)\n",
        "pred_tree = pipeline_model_tr.transform(testDF)"
      ],
      "metadata": {
        "id": "f49I2KVRGIWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_tree.select(\"features\", \"actual_worth\", \"prediction\").show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nbah9sXoGITt",
        "outputId": "b48050ad-c94b-457b-c1db-b6d5351474ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------+------------------+\n",
            "|            features|actual_worth|        prediction|\n",
            "+--------------------+------------+------------------+\n",
            "|[61.0,1.0,0.0,0.0...|    262493.0|  657908.733273964|\n",
            "|[61.0,1.0,0.0,0.0...|    390000.0|  994848.609723248|\n",
            "|[61.0,1.0,0.0,0.0...|    312500.0|  994848.609723248|\n",
            "|[61.0,1.0,0.0,1.0...|    650000.0|1241403.9938946737|\n",
            "|[61.0,1.0,0.0,1.0...|    500000.0|1241403.9938946737|\n",
            "|[61.0,1.0,0.0,1.0...|   1280000.0|1241403.9938946737|\n",
            "|[61.0,1.0,0.0,1.0...|    925000.0|1241403.9938946737|\n",
            "|[61.0,1.0,0.0,1.0...|    250000.0|1241403.9938946737|\n",
            "|[61.0,1.0,0.0,1.0...|   1150000.0|1241403.9938946737|\n",
            "|[61.0,1.0,0.0,1.0...|    750000.0|1241403.9938946737|\n",
            "|[61.0,1.0,0.0,1.0...|    962500.0|1241403.9938946737|\n",
            "|[61.0,1.0,0.0,1.0...|   1500000.0|1241403.9938946737|\n",
            "|[61.0,1.0,0.0,2.0...|    400000.0|  1397628.28283934|\n",
            "|[61.0,1.0,0.0,2.0...|    800000.0|  1397628.28283934|\n",
            "|[61.0,1.0,0.0,2.0...|   1500000.0|  1397628.28283934|\n",
            "|[61.0,1.0,0.0,2.0...|   1400000.0|  1397628.28283934|\n",
            "|[61.0,1.0,0.0,2.0...|    350000.0|  1397628.28283934|\n",
            "|[61.0,1.0,0.0,2.0...|   2200000.0|  1397628.28283934|\n",
            "|[61.0,1.0,0.0,2.0...|   1830000.0|  1397628.28283934|\n",
            "|[61.0,1.0,0.0,2.0...|   1250000.0|  1397628.28283934|\n",
            "+--------------------+------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regression_evaluator_dt = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"actual_worth\", metricName=\"rmse\")\n",
        "\n",
        "rmse_dt = regression_evaluator_dt.evaluate(pred_tree)\n",
        "print(f\"RMSE is {rmse_dt:.1f}\")\n",
        "\n",
        "r2_dt = regression_evaluator_dt.setMetricName(\"r2\").evaluate(pred_tree)\n",
        "print(f\"R2 is {r2_dt}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hua3E3hGIQu",
        "outputId": "d62af061-d2ee-4857-e8ac-0b68c5470c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE is 684472.9\n",
            "R2 is 0.6066181118967662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Regressor**"
      ],
      "metadata": {
        "id": "S3cLfYm5G6Eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(labelCol=\"actual_worth\", featuresCol=\"features\", numTrees=100)\n",
        "pipeline_rf = Pipeline(stages=[string_indexer, ohe_encoder, vec_assembler, rf])\n",
        "rf_model = pipeline_rf.fit(trainDF)\n",
        "rf_predictions = rf_model.transform(testDF)"
      ],
      "metadata": {
        "id": "poEr7EnkGINe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_predictions.select(\"actual_worth\", \"prediction\").show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYx4keszGIKD",
        "outputId": "1b6639bd-3691-445a-95d2-3da8aba6aa8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------------+\n",
            "|actual_worth|        prediction|\n",
            "+------------+------------------+\n",
            "|    262493.0| 1027883.501410307|\n",
            "|    390000.0|1479625.4069014462|\n",
            "|    312500.0|1479625.4069014462|\n",
            "|    650000.0| 1626333.095486657|\n",
            "|    500000.0| 1626333.095486657|\n",
            "|   1280000.0| 1626333.095486657|\n",
            "|    925000.0|1819357.1611668752|\n",
            "|    250000.0|1840634.2916982493|\n",
            "|   1150000.0|1840634.2916982493|\n",
            "|    750000.0|1855998.2875859875|\n",
            "|    962500.0|1855998.2875859875|\n",
            "|   1500000.0|1855998.2875859875|\n",
            "|    400000.0| 2149348.458401745|\n",
            "|    800000.0| 2149348.458401745|\n",
            "|   1500000.0| 2149348.458401745|\n",
            "|   1400000.0| 2149348.458401745|\n",
            "|    350000.0| 2149348.458401745|\n",
            "|   2200000.0| 2149348.458401745|\n",
            "|   1830000.0| 2149348.458401745|\n",
            "|   1250000.0| 2149348.458401745|\n",
            "+------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regression_evaluator_rf = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"actual_worth\", metricName=\"rmse\")\n",
        "\n",
        "rmse_rf = regression_evaluator_rf.evaluate(rf_predictions)\n",
        "print(f\"RMSE is {rmse_rf:.1f}\")\n",
        "\n",
        "r2_rf = regression_evaluator_dt.setMetricName(\"r2\").evaluate(rf_predictions)\n",
        "print(f\"R2 is {r2_rf}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAJlbom1GIAs",
        "outputId": "7c43b1a6-d671-4608-d374-94d436c14825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE is 769806.1\n",
            "R2 is 0.5024180935312009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Boosting Regression**"
      ],
      "metadata": {
        "id": "YLeo_9Suu3Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import GBTRegressor"
      ],
      "metadata": {
        "id": "QOOUnfDxbAD6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
        "\n",
        "gbt = GBTRegressor(featuresCol=\"scaled_features\", labelCol=\"actual_worth\", maxIter=20, maxDepth=5)\n",
        "pipeline_gbt = Pipeline(stages = [string_indexer, ohe_encoder, vec_assembler, scaler, gbt])\n",
        "\n",
        "gbt_model = pipeline_gbt.fit(trainDF)\n",
        "gbt_prediction = gbt_model.transform(testDF)\n",
        "gbt_prediction.select(\"actual_worth\", \"prediction\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBQ24iYgu2qV",
        "outputId": "99b5b480-e2fa-4628-e1e2-411342ebe675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------------+\n",
            "|actual_worth|        prediction|\n",
            "+------------+------------------+\n",
            "|    262493.0| 797174.6433476824|\n",
            "|    390000.0|1240169.7688490453|\n",
            "|    312500.0|1240169.7688490453|\n",
            "|    650000.0|1271423.8822804296|\n",
            "|    500000.0|1271423.8822804296|\n",
            "|   1280000.0|1271423.8822804296|\n",
            "|    925000.0| 1851776.029673512|\n",
            "|    250000.0| 1851776.029673512|\n",
            "|   1150000.0| 1851776.029673512|\n",
            "|    750000.0| 1851776.029673512|\n",
            "+------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_gbt = regression_evaluator.setMetricName(\"rmse\").evaluate(gbt_prediction)\n",
        "print(f\"RMSE is {rmse_gbt:.1f}\")\n",
        "\n",
        "r2_gbt = regression_evaluator.setMetricName(\"r2\").evaluate(gbt_prediction)\n",
        "print(f\"R2 is {r2_gbt}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9vyAOUrMrVn",
        "outputId": "fd751312-0ee2-4447-a12c-ab501da31438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE is 674426.2\n",
            "R2 is 0.6180814123261409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing Bagging**"
      ],
      "metadata": {
        "id": "1B0ioaxT0PrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate_random_df(df):\n",
        "    # number of rows in initial dataframe\n",
        "    num_rows = df.count()\n",
        "    # generate sample from 100% to 200% of initial dataframe\n",
        "    # allow replacement => number of rows in sample can be smaller\n",
        "    fraction = random.uniform(1.0, 2.0)\n",
        "    sampled_df = df.sample(withReplacement=True, fraction=fraction)\n",
        "    # limit sample => number of rows in sample is equal to initial dataframe\n",
        "    sampled_df = sampled_df.limit(num_rows)\n",
        "    return sampled_df"
      ],
      "metadata": {
        "id": "5yDHz3Tjz2KY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_bags = 5\n",
        "samples = []\n",
        "\n",
        "for _ in range(number_of_bags):\n",
        "  samples.append(generate_random_df(trainDF))"
      ],
      "metadata": {
        "id": "PXRquG3eHHH9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create function to prepare data for training\n",
        "def prepare_data(df, label_name):\n",
        "  categorical_cols = [field for (field, dataType) in trainDF.dtypes if dataType == \"string\"]\n",
        "  index_output_cols = [x + \"Index\" for x in categorical_cols]\n",
        "  ohe_output_cols = [x + \"OHE\" for x in categorical_cols]\n",
        "\n",
        "  string_indexer = StringIndexer(inputCols = categorical_cols, outputCols = index_output_cols, handleInvalid = \"skip\")\n",
        "  ohe_encoder = OneHotEncoder(inputCols = index_output_cols, outputCols = ohe_output_cols)\n",
        "\n",
        "  numeric_cols = [field for (field, dataType) in trainDF.dtypes if ((dataType == \"double\") and (field != \"actual_worth\"))]\n",
        "\n",
        "  assembler_inputs = ohe_output_cols + numeric_cols\n",
        "  vec_assembler = VectorAssembler(inputCols = assembler_inputs, outputCol = \"features\")\n",
        "\n",
        "  return string_indexer, ohe_encoder, vec_assembler"
      ],
      "metadata": {
        "id": "A-bdnnCA0q6o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_indexer, ohe_encoder, vec_assembler = prepare_data(samples[0], \"actual_worth\")"
      ],
      "metadata": {
        "id": "4oXMv4L4z2F-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = []\n",
        "predictions = []\n",
        "\n",
        "for sample in samples:\n",
        "  scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
        "\n",
        "  gbt = GBTRegressor(featuresCol=\"scaled_features\", labelCol=\"actual_worth\", maxIter=20, maxDepth=5)\n",
        "  pipeline_gbt = Pipeline(stages = [string_indexer, ohe_encoder, vec_assembler, scaler, gbt])\n",
        "\n",
        "  gbt_model_bag = pipeline_gbt.fit(sample)\n",
        "  models.append(gbt_model_bag)\n",
        "\n",
        "  gbt_prediction_bag = gbt_model_bag.transform(testDF)\n",
        "  predictions.append(gbt_prediction_bag)"
      ],
      "metadata": {
        "id": "ZSaL7QI9z2D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for prediction in predictions:\n",
        "  prediction.select(\"actual_worth\", \"prediction\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRqH0G6sz2BO",
        "outputId": "17ac6002-c8a0-4018-d13a-7d4e301e6d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------------+\n",
            "|actual_worth|        prediction|\n",
            "+------------+------------------+\n",
            "|    262493.0| 718399.2525931613|\n",
            "|    390000.0|1187989.8307684031|\n",
            "|    312500.0|1187989.8307684031|\n",
            "|    650000.0|1598735.4994814058|\n",
            "|    500000.0|1598735.4994814058|\n",
            "+------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+------------+------------------+\n",
            "|actual_worth|        prediction|\n",
            "+------------+------------------+\n",
            "|    262493.0| 676661.2566635377|\n",
            "|    390000.0|1115005.2208664608|\n",
            "|    312500.0|1115005.2208664608|\n",
            "|    650000.0| 1702674.880747555|\n",
            "|    500000.0| 1702674.880747555|\n",
            "+------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+------------+------------------+\n",
            "|actual_worth|        prediction|\n",
            "+------------+------------------+\n",
            "|    262493.0| 785871.4006877741|\n",
            "|    390000.0|1164686.3368624006|\n",
            "|    312500.0|1164686.3368624006|\n",
            "|    650000.0|1724867.9027933925|\n",
            "|    500000.0|1724867.9027933925|\n",
            "+------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate average prediction"
      ],
      "metadata": {
        "id": "PifBaeKe_Ze0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "cumm_predictions = []\n",
        "\n",
        "# rename column \"prediction\" to proceed join operation\n",
        "for i in range(len(predictions)):\n",
        "  df = predictions[i].withColumnRenamed(\"prediction\", f'prediction_{i+1}').withColumn(\"row_id\", F.monotonically_increasing_id())\n",
        "\n",
        "  # remove column \"actual_worth\" in all dataframes except the first for join operation\n",
        "  if i > 0:\n",
        "    df = df.drop(\"actual_worth\")\n",
        "  cumm_predictions.append(df)\n",
        "\n",
        "# join all predictions from all bags\n",
        "predictions_joined = cumm_predictions[0].alias('df1')\n",
        "for i in range(1, len(cumm_predictions)):\n",
        "  predictions_joined = predictions_joined.join(cumm_predictions[i].alias(f'df{i+1}'), on=\"row_id\")\n",
        "\n",
        "# create a list of columns with predictions\n",
        "prediction_columns = [f'df{i+1}.prediction_{i+1}' for i in range(len(cumm_predictions))]\n",
        "\n",
        "# calculate average value for a particular item\n",
        "average_expression = sum(F.col(col) for col in prediction_columns) / len(prediction_columns)\n",
        "\n",
        "prediction_avg = predictions_joined.withColumn(\"average_prediction\", average_expression)"
      ],
      "metadata": {
        "id": "MXByCeCzz1-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_avg.select(\"actual_worth\", \"average_prediction\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOwAczsGU6Wt",
        "outputId": "df81e0ed-093a-4bf9-e4ac-4df57b3fb6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------------+\n",
            "|actual_worth|average_prediction|\n",
            "+------------+------------------+\n",
            "|    262493.0| 758735.2904626172|\n",
            "|    390000.0|1181200.9567657362|\n",
            "|    312500.0|1181200.9567657362|\n",
            "|    650000.0|1427096.5135852583|\n",
            "|    500000.0|1566624.8321848188|\n",
            "+------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regression_evaluator_bag = RegressionEvaluator(predictionCol=\"average_prediction\", labelCol=\"actual_worth\", metricName=\"rmse\")\n",
        "\n",
        "rmse_bag = regression_evaluator_bag.evaluate(prediction_avg)\n",
        "print(f\"RMSE is {rmse_bag:.1f}\")\n",
        "\n",
        "r2_bag = regression_evaluator_bag.setMetricName(\"r2\").evaluate(prediction_avg)\n",
        "print(f\"R2 is {r2_bag}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUJxi0kIz18J",
        "outputId": "74ccc833-b130-4648-b435-74305bcba4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE is 650903.4\n",
            "R2 is 0.6227564928113317\n"
          ]
        }
      ]
    }
  ]
}