{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**10-fold cross-validation with the Gradient Boosting Regression model**"
      ],
      "metadata": {
        "id": "TD6bS2TQSxAG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sqZvQLubSr65"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('DLD_project_cross').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive_new')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UrQVgNzS-ZF",
        "outputId": "dc57ae9f-72b0-4265-a2ba-3fde3501da76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive_new\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"parquet\").load(\"/content/drive_new/MyDrive/cleaned_dataset\")"
      ],
      "metadata": {
        "id": "5_-ADbAGS-0l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = df.randomSplit([1.0] * 10)"
      ],
      "metadata": {
        "id": "GBEHW0YDTA4b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.feature import VectorAssembler, OneHotEncoder, StringIndexer, StandardScaler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.regression import GBTRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "categorical_cols = [field for (field, dataType) in df.dtypes if dataType == \"string\"]\n",
        "index_output_cols = [x + \"Index\" for x in categorical_cols]\n",
        "ohe_output_cols = [x + \"OHE\" for x in categorical_cols]\n",
        "\n",
        "string_indexer = StringIndexer(inputCols = categorical_cols, outputCols = index_output_cols, handleInvalid = \"skip\")\n",
        "ohe_encoder = OneHotEncoder(inputCols = index_output_cols, outputCols = ohe_output_cols)\n",
        "\n",
        "numeric_cols = [field for (field, dataType) in df.dtypes if ((dataType == \"double\") and (field != \"actual_worth\"))]\n",
        "\n",
        "assembler_inputs = ohe_output_cols + numeric_cols\n",
        "vec_assembler = VectorAssembler(inputCols = assembler_inputs, outputCol = \"features\")\n",
        "\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
        "\n",
        "gbt = GBTRegressor(featuresCol=\"scaled_features\", labelCol=\"actual_worth\", maxIter=20, maxDepth=5)\n",
        "pipeline_gbt = Pipeline(stages = [string_indexer, ohe_encoder, vec_assembler, scaler, gbt])"
      ],
      "metadata": {
        "id": "n4C8DILMjGTq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = df.schema\n",
        "errors_rmse = []\n",
        "errors_r2 = []\n",
        "\n",
        "for i in range(len(splits)):\n",
        "  test_df = splits[i]\n",
        "  train_df = spark.createDataFrame(spark.sparkContext.emptyRDD(), schema)\n",
        "\n",
        "  for j in range(len(splits)):\n",
        "    if j != i:\n",
        "      train_df = train_df.union(splits[j])\n",
        "\n",
        "  pipeline_model_gbt = pipeline_gbt.fit(train_df)\n",
        "  prediction_gbt = pipeline_model_gbt.transform(test_df)\n",
        "\n",
        "  regression_evaluator_gbt = RegressionEvaluator(predictionCol = \"prediction\", labelCol = \"actual_worth\", metricName = \"rmse\")\n",
        "  rmse_dt = regression_evaluator_gbt.evaluate(prediction_gbt)\n",
        "  r2_dt = regression_evaluator_gbt.setMetricName(\"r2\").evaluate(prediction_gbt)\n",
        "  errors_rmse.append(rmse_dt)\n",
        "  errors_r2.append(r2_dt)"
      ],
      "metadata": {
        "id": "T_E-imdGi8dX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_rmse_error = sum(errors_rmse) / len(errors_rmse)\n",
        "average_r2_error = sum(errors_r2) / len(errors_r2)\n",
        "\n",
        "print(f\"Average RMSE: {average_rmse_error:.4f}\")\n",
        "print(f\"Average R2: {average_r2_error:.4f}\")"
      ],
      "metadata": {
        "id": "P1UodvTgl0la",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe837487-2f2c-4c9b-b84f-1e96ba90fea2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average RMSE: 677974.3822\n",
            "Average R2: 0.6150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10-fold cross-validation with the Decision tree model**"
      ],
      "metadata": {
        "id": "Me6aHjzhEDlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "\n",
        "assembler_inputs_tree = index_output_cols + numeric_cols\n",
        "vec_assembler_tree = VectorAssembler(inputCols=assembler_inputs_tree, outputCol=\"features\")\n",
        "\n",
        "dt = DecisionTreeRegressor(labelCol=\"actual_worth\", featuresCol=\"features\")\n",
        "dt.setMaxBins(135)\n",
        "\n",
        "stages_tree = [string_indexer, vec_assembler_tree, dt]\n",
        "pipeline_tr = Pipeline(stages=stages_tree)"
      ],
      "metadata": {
        "id": "gHntCilgDRYl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors_dt_rmse = []\n",
        "errors_dt_r2 = []\n",
        "\n",
        "for i in range(len(splits)):\n",
        "  test_df = splits[i]\n",
        "  train_df = spark.createDataFrame(spark.sparkContext.emptyRDD(), schema)\n",
        "\n",
        "  for j in range(len(splits)):\n",
        "    if j != i:\n",
        "      train_df = train_df.union(splits[j])\n",
        "\n",
        "  pipeline_model_dt = pipeline_tr.fit(train_df)\n",
        "  prediction_dt = pipeline_model_dt.transform(test_df)\n",
        "\n",
        "  regression_evaluator_dt = RegressionEvaluator(predictionCol = \"prediction\", labelCol = \"actual_worth\", metricName = \"rmse\")\n",
        "  rmse_dt = regression_evaluator_dt.evaluate(prediction_dt)\n",
        "  r2_dt = regression_evaluator_dt.setMetricName(\"r2\").evaluate(prediction_dt)\n",
        "  errors_dt_rmse.append(rmse_dt)\n",
        "  errors_dt_r2.append(r2_dt)"
      ],
      "metadata": {
        "id": "jWWz0KauDa6E"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_dt_rmse_error = sum(errors_dt_rmse) / len(errors_dt_rmse)\n",
        "average_dt_r2_error = sum(errors_dt_r2) / len(errors_dt_r2)\n",
        "\n",
        "print(f\"Average RMSE: {average_dt_rmse_error:.4f}\")\n",
        "print(f\"Average R2: {average_dt_r2_error:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XABnEq5EwoI",
        "outputId": "8d19b7e1-28f0-46ce-e479-7d84027eae20"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average RMSE: 686825.5547\n",
            "Average R2: 0.6049\n"
          ]
        }
      ]
    }
  ]
}